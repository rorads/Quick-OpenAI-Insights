{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/Quick-OpenAI-Insights\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and load dotenv - required for loading environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"text\": \" lazy dog.\"\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1677599112,\n",
      "  \"id\": \"cmpl-6owS8o2XhbR45f8kTCeQbXmJvzXML\",\n",
      "  \"model\": \"davinci\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 3,\n",
      "    \"prompt_tokens\": 30,\n",
      "    \"total_tokens\": 33\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# import openai and use the autocomplete api\n",
    "import openai\n",
    "\n",
    "# openai key already set throuhg environment variable\n",
    "\n",
    "# prompt for the autocomplete api\n",
    "prompt = \"\"\"This is a test of the autocomplete API. Please confirm that it works by completing the following sentence: \"The quick brown fox jumps over the\"\"\"\n",
    "\n",
    "# call the autocomplete api\n",
    "response = openai.Completion.create(\n",
    "    engine=\"davinci\",\n",
    "    prompt=prompt,\n",
    "    temperature=0.9,\n",
    "    max_tokens=100,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0.6,\n",
    "    stop=[\"\\\"\"]\n",
    ")\n",
    "\n",
    "# print the response\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the data/intermediate folder, load the preprocessed json data into a dataframe (with orient='records')\n",
    "df = pd.read_json('data/intermediate/processed.json', orient='records', lines=True)\n",
    "\n",
    "def make_prompt(text: str):\n",
    "    \"\"\"\n",
    "    Returns a prompt for the autocomplete api with a pre-defined json structure and the text to summarize.\n",
    "    Args:\n",
    "        text (str): the text to summarize\n",
    "    \"\"\"\n",
    "    prompt = \"\"\"\n",
    "    What follows is a chunk of text. I want you to return a json string with the following structure:\n",
    "    {{\n",
    "        \"topic\": \"a one word topic for the text\",\n",
    "        \"tags\": \"a space separated list of tags for the text\",\n",
    "        \"sentiment\": \"a sentiment score for the text, ranging from -1 to 1\",\n",
    "        \"urgency\": \"an urgency score for the text, ranging from 0 to 1, where 0 is not urgent and 1 is very urgent\",\n",
    "    }}\n",
    "\n",
    "    text:\n",
    "    \\\"\\\"\\\"\n",
    "    {}\n",
    "    \\\"\\\"\\\"\n",
    "    \"\"\".format(text)\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    What follows is a chunk of text. I want you to return a json string with the following structure:\n",
      "    {\n",
      "        \"topic\": \"a one word topic for the text\",\n",
      "        \"tags\": \"a space separated list of tags for the text\",\n",
      "        \"sentiment\": \"a sentiment score for the text, ranging from -1 to 1\",\n",
      "        \"urgency\": \"an urgency score for the text, ranging from 0 to 1, where 0 is not urgent and 1 is very urgent\",\n",
      "    }\n",
      "\n",
      "    text:\n",
      "    \"\"\"\n",
      "    all right thanks yeah thank you very much and thank you for hosting this Market engagement event\n",
      "    \"\"\"\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "new_prompt = make_prompt(df['text'][4])\n",
    "print(new_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    {\n",
      "        \"topic\": \"Thanks\",\n",
      "        \"tags\": \"engagement event, Market\",\n",
      "        \"sentiment\": \"0.8\",\n",
      "        \"urgency\": \"0.3\"\n",
      "    }\n"
     ]
    }
   ],
   "source": [
    "# call the autocomplete api using the make_prompt function\n",
    "response = openai.Completion.create(\n",
    "    engine=\"text-davinci-003\",\n",
    "    prompt=make_prompt(df.text[4]),\n",
    "    temperature=0.7,\n",
    "    max_tokens=100,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0\n",
    ")\n",
    "\n",
    "# print the response\n",
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".ve",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "74e479d9ae72adc706e45e5e5d75a92fa67b768ef72f999bca0140337ff9ea7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
